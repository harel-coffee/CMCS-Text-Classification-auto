{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HimashiRathnayake/CMCS-Text-Classification/blob/main/Adapter_Based_Fine_Tuning/Sentence_Level_Tasks_Adapter_Based_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoL8-pXx9z7c"
      },
      "source": [
        "## Training Single Task Adapters \n",
        "For Bert SinBert and XLM-R Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "KSLx_mnliOvH",
        "outputId": "31c1c5a2-b897-4035-dd66-cfa439898419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device name\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla K80'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "print(\"GPU Device name\")\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCdvw5JNlygg"
      },
      "source": [
        "### **Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LjxhVXklun6"
      },
      "outputs": [],
      "source": [
        "model_type = \"XLM-R\" #@param [\"SinBERT\", \"Bert\", \"XLM-R\"]\n",
        "technique = \"humor\" #@param [\"humor\", \"hate speech\", \"sentiment\"]\n",
        "load_adapter = False #@param {type:\"boolean\"}\n",
        "# train = True #@param {type:\"boolean\"}\n",
        "unfreeze_model = False #@param {type:\"boolean\"}\n",
        "save_adapter = False #@param {type:\"boolean\"}\n",
        "oversample_dataset = False #@param {type:\"boolean\"}\n",
        "lang_adapter_setting = \"stack\" #@param [\"none\", \"stack\", \"parallel\"]\n",
        "random_state = 43 #@param\n",
        "adapter_config = \"pfeiffer\" #@param [\"houlsby\", \"pfeiffer\"]\n",
        "over_sampling_technique = \"ROS\" #@param [\"\", \"ROS\",\"ADASYN\", \"SMOTE\", \"BorderlineSMOTE\"]\n",
        "sampling_strategy = \"1:0.25:0.25\" #@param [] {allow-input: true} \n",
        "## eg: 1:0.25:0.25 for hate | 0.5 for humor | 1:1:1:1 or 0.5:1:0.5:0.5 or 0.25:1:0.25:0.25 for sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KanOOHjzWI7b"
      },
      "outputs": [],
      "source": [
        "pretrained_adapter_path = \"/content/drive/Shareddrives/FYP/TrainedAdapters/opt_bert_sinBert_task_adapter_\"+technique #+ \"_\" + str(random_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L9gYpCV28OA"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qL3Sq1HQynCq"
      },
      "outputs": [],
      "source": [
        "# !pip install -U adapter-transformers\n",
        "# !pip install datasets\n",
        "# !pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUHpDE_Gtyen"
      },
      "source": [
        "### Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJZ6z8bJl25l"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelWithHeads, TrainingArguments, AdapterTrainer, EvalPrediction, TextClassificationPipeline, AdapterConfig, EarlyStoppingCallback, Trainer\n",
        "from transformers.adapters.composition import Fuse, Stack, Parallel\n",
        "from datasets import load_metric\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, BorderlineSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDIvwCzMP_WF",
        "outputId": "b26822da-3726-48c7-adf1-fa4284628220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzrDM6Ua-jo_"
      },
      "source": [
        "### Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BB8pw1RDuDaA"
      },
      "outputs": [],
      "source": [
        "def apply_oversampling(x, y):\n",
        "\n",
        "  (unique, counts) = np.unique(y, axis=0, return_counts=True)\n",
        "  print(\"Class Distribution Without Oversampling\", counts)\n",
        "\n",
        "  # define oversampling strategy\n",
        "  if (over_sampling_technique == \"\"):\n",
        "    return x, y\n",
        "  elif (over_sampling_technique == \"ROS\"):\n",
        "    if (technique==\"humor\"):\n",
        "      oversample = RandomOverSampler(sampling_strategy = float(sampling_strategy))\n",
        "    elif (technique==\"hate speech\"):\n",
        "      sampling_ratio = sampling_strategy.split(\":\");\n",
        "      oversample = RandomOverSampler(sampling_strategy = {\n",
        "          0:int(counts[0]*float(sampling_ratio[0])), \n",
        "          1:int(counts[0]*float(sampling_ratio[1])), \n",
        "          2:int(counts[0]*float(sampling_ratio[2]))\n",
        "          })\n",
        "    elif (technique==\"sentiment\"):\n",
        "      sampling_ratio = sampling_strategy.split(\":\");\n",
        "      oversample = RandomOverSampler(sampling_strategy = {\n",
        "          0:int(counts[1]*float(sampling_ratio[0])), \n",
        "          1:int(counts[1]*float(sampling_ratio[1])), \n",
        "          2:int(counts[1]*float(sampling_ratio[2])),\n",
        "          3:int(counts[1]*float(sampling_ratio[3]))\n",
        "          })\n",
        "  elif (over_sampling_technique == \"ADASYN\"):\n",
        "    oversample = ADASYN(sampling_strategy=\"minority\")\n",
        "  elif (over_sampling_technique == \"SMOTE\"):\n",
        "    oversample = SMOTE()\n",
        "  elif (over_sampling_technique == \"BorderlineSMOTE\"):\n",
        "    oversample = BorderlineSMOTE()\n",
        "\n",
        "  # fit and apply the transform\n",
        "  X_over, y_over = oversample.fit_resample(x, y)\n",
        "\n",
        "  (unique, counts) = np.unique(y_over, axis=0, return_counts=True)\n",
        "  print(\"Class Distribution After Oversampling\", counts)\n",
        "\n",
        "  return X_over, y_over"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MUpioPlmvMh"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/drive/Shareddrives/FYP/corpus/Ã§ompleted_draft.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yq5AMmjelqlj"
      },
      "outputs": [],
      "source": [
        "all_data = pd.read_csv(dataset_path)\n",
        "\n",
        "if (technique == \"humor\"):\n",
        "  all_data = all_data[['Sentence', 'Humor']]\n",
        "elif (technique == \"hate speech\"):\n",
        "  all_data = all_data[['Sentence', 'Hate_speech']]\n",
        "else:\n",
        "  all_data = all_data[['Sentence', 'Sentiment']]\n",
        "\n",
        "all_data.columns = ['Sentence', 'Label']\n",
        "all_data['Label'], uniq = pd.factorize(all_data['Label'])\n",
        "\n",
        "X = all_data['Sentence'].values.tolist()\n",
        "y = all_data['Label'].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQp6K1g3mVrn"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = random_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYKAypzh_r3j"
      },
      "outputs": [],
      "source": [
        "if oversample_dataset:\n",
        "  # apply oversampling\n",
        "  X_train = np.array(X_train).reshape(-1, 1)\n",
        "  X_train, y_train = apply_oversampling(X_train, y_train)\n",
        "  X_train = [x[0] for x in X_train.tolist()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E34vJVEc65nS"
      },
      "source": [
        "## **Tokenizing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCUWfe8-n0i8"
      },
      "outputs": [],
      "source": [
        "if (model_type==\"SinBERT\"):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/Shareddrives/FYP/Bert/SinBERT_large\")\n",
        "elif (model_type==\"Bert\"):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "else:\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\", do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqXJtJe8oObQ"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 128\n",
        "\n",
        "def encode_batch(batch):\n",
        "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
        "  return tokenizer(batch, max_length=MAX_LEN, truncation=True, padding=\"max_length\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcwOeBZyov3K"
      },
      "outputs": [],
      "source": [
        "# Encode the input data\n",
        "encoded_X_train = encode_batch(X_train)\n",
        "encoded_X_test = encode_batch(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6581Al-K_Nyf"
      },
      "outputs": [],
      "source": [
        "class DatasetObject(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = DatasetObject(encoded_X_train, y_train)\n",
        "test_dataset = DatasetObject(encoded_X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCwk6iQE_XZb"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEiosRF68JMq"
      },
      "outputs": [],
      "source": [
        "if (technique == 'humor'):\n",
        "    num_labels=2\n",
        "    id2label={ 0: \"Non-humorous\", 1: \"Humorous\"}\n",
        "elif (technique == 'hate speech'):\n",
        "    num_labels=3\n",
        "    id2label={ 0: \"Not offensive\", 1: \"Hate-Inducing\", 2: \"Abusive\"}\n",
        "else:\n",
        "    num_labels=4\n",
        "    id2label={ 0: \"Positive\", 1: \"Negative\", 2: \"Neutral\", 3:\"Conflict\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNyi1nFH_TOS",
        "outputId": "a9bec750-461c-4fcb-e00e-615ab0242be6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/adapters/models/roberta.py:255: FutureWarning: This class has been renamed to `RobertaModelWithHeads` in v3. Please use the new class instead as this class might be removed in a future version.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/adapters/models/roberta.py:233: FutureWarning: This class has been renamed to `RobertaModelWithHeads` in v3. Please use the new class instead as this class might be removed in a future version.\n",
            "  FutureWarning,\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing XLMRobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaModelWithHeads were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "if (model_type==\"SinBERT\"):\n",
        "  config = AutoConfig.from_pretrained(\"/content/drive/Shareddrives/FYP/Bert/SinBERT_large\", num_labels= num_labels)\n",
        "  model = AutoModelWithHeads.from_pretrained(\"/content/drive/Shareddrives/FYP/Bert/SinBERT_large\", config=config)\n",
        "elif (model_type==\"Bert\"):\n",
        "  config = AutoConfig.from_pretrained(\"bert-base-uncased\", num_labels= num_labels)\n",
        "  model = AutoModelWithHeads.from_pretrained(\"bert-base-uncased\", config=config)\n",
        "else:\n",
        "  config = AutoConfig.from_pretrained(\"xlm-roberta-base\", num_labels=num_labels)\n",
        "  model = AutoModelWithHeads.from_pretrained(\"xlm-roberta-base\", config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RPhSipb_diC",
        "outputId": "3bc6b904-dbf9-4482-aec2-c63e1896ca80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adding new adapter pfeiffer\n"
          ]
        }
      ],
      "source": [
        "# Load an adapter  \n",
        "if load_adapter:\n",
        "  print(\"loading adapter from\", pretrained_adapter_path)\n",
        "  model.load_adapter(pretrained_adapter_path, with_head=False)\n",
        "\n",
        "# Add a new adapter  \n",
        "else:\n",
        "  print(\"adding new adapter\", adapter_config)\n",
        "  if adapter_config == \"pfeiffer\":\n",
        "    config = AdapterConfig.load(\"pfeiffer\", reduction_factor=12)\n",
        "  else:\n",
        "    config = AdapterConfig.load(\"houlsby\")\n",
        "  model.add_adapter(\"task_\"+technique, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zq1dG4sVcDX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7f024ff-1d55-4ede-b875-2261ee97b9fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stacking language adapters\n"
          ]
        }
      ],
      "source": [
        "# Add a classification head\n",
        "model.add_classification_head(\n",
        "  \"task_\"+technique,\n",
        "  num_labels=num_labels,\n",
        "  id2label=id2label\n",
        ")\n",
        "\n",
        "# Without Language Adapters\n",
        "if lang_adapter_setting == \"none\":\n",
        "  model.set_active_adapters(\"task_\"+technique)\n",
        "\n",
        "else:\n",
        "  # Load language adapters\n",
        "  lang_adapter_config = AdapterConfig.load(\"pfeiffer+inv\")\n",
        "  model.load_adapter(\"/content/drive/Shareddrives/FYP/TrainedAdapters/mlm\", config=lang_adapter_config, load_as=\"si-en\", with_head=False)\n",
        "  # model.load_adapter(\"/content/drive/Shareddrives/FYP/TrainedAdapters/si_mlm\", config=lang_adapter_config, load_as=\"si\", with_head=False)\n",
        "  model.load_adapter(\"/content/drive/Shareddrives/FYP/final_adapter/sinbert-lang-adapter/mlm\", config=lang_adapter_config, load_as=\"si\", with_head=False)\n",
        "  config = AdapterConfig.load(\"pfeiffer\", non_linearity=\"relu\", reduction_factor=2)\n",
        "  model.load_adapter(\"en/wiki@ukp\", config=config)\n",
        "  \n",
        "  # Stack Language Adapters\n",
        "  if lang_adapter_setting == \"stack\":\n",
        "    print(\"stacking language adapters\")\n",
        "    model.set_active_adapters(Stack(\"en\", \"si\", \"si-en\", \"task_\"+technique))\n",
        "\n",
        "  # Parallel Language Adapters\n",
        "  else:\n",
        "    print(\"stacking parallel language adapters set\")\n",
        "    model.set_active_adapters(Stack(Parallel(\"en\", \"si\", \"si-en\"), \"task_\"+technique))\n",
        "\n",
        "# Train Adapter\n",
        "model.train_adapter(\"task_\"+technique)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the model to train both the model and adapter\n",
        "if unfreeze_model:\n",
        "  model.freeze_model(False)"
      ],
      "metadata": {
        "id": "iVTWkQaiiuhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNAHk2IE_fgS"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    learning_rate=5e-4,\n",
        "    num_train_epochs=6,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    # logging_steps=200,\n",
        "    output_dir=\"./training_output\",\n",
        "    # overwrite_output_dir=True,\n",
        "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
        "    remove_unused_columns=False,\n",
        "    metric_for_best_model=\"eval_macro_f1\",\n",
        "    load_best_model_at_end=True,\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# def compute_accuracy(p: EvalPrediction):\n",
        "#   preds = np.argmax(p.predictions, axis=1)\n",
        "#   return {\"acc\": (preds == p.label_ids).mean()}\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    metric1 = load_metric(\"precision\")\n",
        "    metric2 = load_metric(\"recall\")\n",
        "    metric3 = load_metric(\"f1\")\n",
        "    metric4 = load_metric(\"accuracy\")\n",
        "    \n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    precision = metric1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"precision\"]\n",
        "    recall = metric2.compute(predictions=predictions, references=labels, average=\"weighted\")[\"recall\"]\n",
        "    f1 = metric3.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n",
        "    accuracy = metric4.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    macro_precision = metric1.compute(predictions=predictions, references=labels, average=\"macro\")[\"precision\"]\n",
        "    macro_recall = metric2.compute(predictions=predictions, references=labels, average=\"macro\")[\"recall\"]\n",
        "    macro_f1 = metric3.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n",
        "    return {\"accuracy\":accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"macro_precision\": macro_precision, \"macro_recall\": macro_recall, \"macro_f1\": macro_f1}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuqQODvG_kB-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d3262a0-30c5-4aee-8faf-202170026dae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 12166\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2286\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2286' max='2286' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2286/2286 38:31, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.183582</td>\n",
              "      <td>0.936391</td>\n",
              "      <td>0.936822</td>\n",
              "      <td>0.936391</td>\n",
              "      <td>0.923722</td>\n",
              "      <td>0.939750</td>\n",
              "      <td>0.686739</td>\n",
              "      <td>0.751740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.245100</td>\n",
              "      <td>0.172273</td>\n",
              "      <td>0.937130</td>\n",
              "      <td>0.931279</td>\n",
              "      <td>0.937130</td>\n",
              "      <td>0.930651</td>\n",
              "      <td>0.866438</td>\n",
              "      <td>0.740737</td>\n",
              "      <td>0.787059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.203500</td>\n",
              "      <td>0.172765</td>\n",
              "      <td>0.940828</td>\n",
              "      <td>0.935875</td>\n",
              "      <td>0.940828</td>\n",
              "      <td>0.935190</td>\n",
              "      <td>0.877398</td>\n",
              "      <td>0.756185</td>\n",
              "      <td>0.802079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.176466</td>\n",
              "      <td>0.940828</td>\n",
              "      <td>0.935875</td>\n",
              "      <td>0.940828</td>\n",
              "      <td>0.935190</td>\n",
              "      <td>0.877398</td>\n",
              "      <td>0.756185</td>\n",
              "      <td>0.802079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.197435</td>\n",
              "      <td>0.944527</td>\n",
              "      <td>0.941387</td>\n",
              "      <td>0.944527</td>\n",
              "      <td>0.937909</td>\n",
              "      <td>0.910387</td>\n",
              "      <td>0.751537</td>\n",
              "      <td>0.807233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.152000</td>\n",
              "      <td>0.195219</td>\n",
              "      <td>0.940828</td>\n",
              "      <td>0.935935</td>\n",
              "      <td>0.940828</td>\n",
              "      <td>0.936351</td>\n",
              "      <td>0.866005</td>\n",
              "      <td>0.769582</td>\n",
              "      <td>0.808406</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./training_output/checkpoint-381\n",
            "Configuration saved in ./training_output/checkpoint-381/config.json\n",
            "Model weights saved in ./training_output/checkpoint-381/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./training_output/checkpoint-762\n",
            "Configuration saved in ./training_output/checkpoint-762/config.json\n",
            "Model weights saved in ./training_output/checkpoint-762/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./training_output/checkpoint-1143\n",
            "Configuration saved in ./training_output/checkpoint-1143/config.json\n",
            "Model weights saved in ./training_output/checkpoint-1143/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./training_output/checkpoint-1524\n",
            "Configuration saved in ./training_output/checkpoint-1524/config.json\n",
            "Model weights saved in ./training_output/checkpoint-1524/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./training_output/checkpoint-1905\n",
            "Configuration saved in ./training_output/checkpoint-1905/config.json\n",
            "Model weights saved in ./training_output/checkpoint-1905/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./training_output/checkpoint-2286\n",
            "Configuration saved in ./training_output/checkpoint-2286/config.json\n",
            "Model weights saved in ./training_output/checkpoint-2286/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./training_output/checkpoint-2286 (score: 0.8084063146557832).\n"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Frvx7oS5APqa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "a10f5a69-7dce-49e8-9e63-dc949db613d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [43/43 00:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 6.0,\n",
              " 'eval_accuracy': 0.9408284023668639,\n",
              " 'eval_f1': 0.9363514990456706,\n",
              " 'eval_loss': 0.1952187418937683,\n",
              " 'eval_macro_f1': 0.8084063146557832,\n",
              " 'eval_macro_precision': 0.8660051082359838,\n",
              " 'eval_macro_recall': 0.7695818710023623,\n",
              " 'eval_precision': 0.9359346240932435,\n",
              " 'eval_recall': 0.9408284023668639,\n",
              " 'eval_runtime': 22.2463,\n",
              " 'eval_samples_per_second': 60.774,\n",
              " 'eval_steps_per_second': 1.933}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "results = trainer.evaluate()\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-A-a4xohqZd"
      },
      "outputs": [],
      "source": [
        "# import csv\n",
        "\n",
        "# with open('/content/drive/Shareddrives/FYP/Results/bert_pfeiffer_TA_'+technique+'.csv', 'a') as f:\n",
        "#     # create the csv writer\n",
        "#     writer = csv.writer(f)\n",
        "\n",
        "#     # write a row to the csv file\n",
        "#     writer.writerow([random_state, results['eval_accuracy'], results['eval_macro_precision'], results['eval_macro_recall'], results['eval_macro_f1']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3U0IIfyBM7b"
      },
      "outputs": [],
      "source": [
        "# classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer, device=training_args.device.index)\n",
        "\n",
        "# classifier(\"LolðŸ˜…\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jjacTz4P1Id"
      },
      "outputs": [],
      "source": [
        "if save_adapter:\n",
        "  model.save_adapter(\"/content/drive/Shareddrives/FYP/TrainedAdapters/Final/xlmr_task_adapter_parallel_\"+technique, \"task_\"+technique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xB7IEuOXWA-X"
      },
      "outputs": [],
      "source": [
        "# classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer, device=training_args.device.index)\n",
        "\n",
        "# classifier(\"This is great!\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cDt4io7IkKU3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Sentence Level Tasks Adapter Based Fine Tuning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}